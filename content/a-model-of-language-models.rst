my model of language models
###########################
:date: 2025-04-03 13:09
:author: admin
:category: Uncategorized
:slug: a-model-of-language-models
:status: published
:save_as: 2025/04/03/a-model-of-language-models/index.html
:url: 2025/04/03/a-model-of-language-models/

The wordcel versus shape rotator debate was a brief but amusing moment of online faux antagonism. There is a natural human tendency to collapse all experience into a unidimensional continuum (or, if you're attempting to show an unusual amount of intellectual rigor, a four-quadrant chart), and this was a good one: a germ of an empirically observed neurological difference flowered into a blooming meadow of cliches. Masculine Nietzchean autists versus effeminate silvertongued jurists! Everyone could find a reflection of themselves and a satisfying new antagonism to complement it. Jocks versus nerds! Except only for nerds.

Discussing the spectrum that stretches from 3D packing problems to outright aphantasia also turns out to be a captivating way to interrogate differences in individuals' phenomenal experience--a tough thing to discuss in an anything-less-than-oblique way. The question was grounded in capabilities and deficits that were satisfyingly hard to question, and which could be felt even within a single person. If it lacked the calibrated pop of the black-versus-blue-dress meme, it was at least relatable enough to still be compelling. I certainly feel like I've experienced varying levels of shape-rotation over my life, or even over the course of each morning's coffee regimen.

The wordcel pole of the discussion remained underspecified. Maybe that was baked in from the start: a specific capability versus a referential pun. Each a perfect reflection of their camp, but still: what the fuck is a wordcel. It didn't matter. Most of the people indulging in discussions like this one felt like they sort of knew, and would self-identify as wordcels, and reductive introspection is only fun as far as it goes.

But I've been thinking about the missing parts of this framing more as I use LLMs to do work. Anyone who does will soon recoil from the idea that they are just "fancy autocomplete." They can do so much more! And yet now, as returns to scale diminish and the allegedly-breakneck pace of innovation increasingly focuses on improvements in efficiency, intensity, or integrations, rather than gains in apples-to-apples frontier capability, it feels as though we can begin to more fruitfully consider what these things are.

I'm sort of coming back around to "fancy autocomplete", but with the caveat that autocomplete turns out to be vastly more powerful than we ever gave it credit for. That a language, with its enforcement of logic and baked-in semantic relationships, can, if authentically implemented, constitute a processing function of much greater capability than most of us ever imagined.

It's as if I dumped the contents of a tent cinch sack in front of my daughter's Cub Scout den. As delightful as they are, I would not expect those kindergarteners to survive long in the wild (though we are working on this!). But if I told them they could take all the time they need but must use all of the pieces in the bag, and not break any, and put them all together into one thing that seems to make sense, they would be surprisingly likely to assemble a pretty good shelter thanks to the capabilities, limits, and functions that are inherent in those components thanks to countless iterations and unseen designers.

I used to think of language like a diagrammed sentence: a logical system with constraints, but not much more than an floppy skeleton of a thing. Fundamentally, a wrapper for some deeper realm of meaning. A computer system could emulate language with a Markov chain or something similar, but without connection to some underlying significance it would be a sterile exercise in embodying a complex system (and even an intellectually unsatisfying one, given the system's provable imperfections). *Text generation* could be thought of alongside *ray-tracing*: complicated ways of modeling the world that hold considerable technical interest, but which had obvious limitations preventing their use for accessing deeper insight.

This idea of language as an imperfect vessel for meaning fascinated me as a neurotic high school student. My inner monologue was ceaseless, and I blamed it for a lot of things I disliked about myself. Perhaps I was bad at soccer because I narrated my planned actions as the ball bounced my way. Perhaps I was bad at charming people because of the latency and artificiality introduced by composing conversational responses. I tried to suppress the tendency, seeking a more reflexive, direct, and uncalculated mode of reaction. Now, many years later, I realize I must have succeeded in this effort, through some combination of effort, biological decay, and mounting boredom with the sound of my own (inner) voice.

I regret pursuing that project, and all the more so if these guesses are right and what I was trying to abandon truly was as powerful as LLMs now suggest. Lots of people have pondered what humans would be without language, and my sense is that the most grandiose ideas about this (in the Sapir Whorf vein) are out of fashion. I am not qualified to say--I have to admit that my linguistics classes seemed the most impenetrable of all the philosophy I took.

But I do think the power and primacy of language is strangely missing from discussions of AI, which tend to be expressed in terms of reasoning and imagination, and chains of tokens, rather than assembling constructs within the rules of a system just a little beyond our understanding--a bag of tent parts that will often pop into the right shape.

I think we may come to understand these systems as embodiments of a capability we knew was important, but which we could never cleanly untangle from the rest of our minds. These things are not thinking beings, not beings or thought at all. They are pure language: a tool more powerful than we'd imagined, but (almost certainly) less capable than the singularists project. With their help, we will unlock the power of language systems in ways humans brains cannot--bigger context windows, faster speeds--and probably deliver at least some superhuman returns as a result. But I wonder if we will find insights of a dramatically new sort. Those might still have to come from whatever part of us is not devoted to wet, fancy autocomplete.
